{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to decision Trees - HOMEWORK\n",
    "\n",
    "Consider the dataset shown in the following cell that outlines how likely a person is to eat a food on the basis of three characteristics. A decision tree works in the following way. It loops over every attribute (taste, temperature, texture) and then calculates the information gained (which is the mutual information) for each potential splitting. It then splits the data along the attribute that creates the largest information gain. \n",
    "\n",
    "Suppose X is the distribution of 'yes', 'no' responses without any splits. If you split on the basis of 'taste', you will end up with three classes. You can then calculate the conditional entropy H(X|taste) and use this to calculate the information gain\n",
    "\n",
    "$ I(X,taste) = H(X) - H(X|taste) $ .\n",
    "\n",
    "Recall that one formulation of the conditional entropy (the one useful here) is\n",
    "\n",
    "$$ H(X|taste) = \\displaystyle \\sum_{t \\in taste} p(t) H(X|taste=t)  $$\n",
    "\n",
    "where the last quantity $H(X|taste = t)$ can be calculated within the propsed class. \n",
    "\n",
    "TASK: For this data, calculate and output the information gained by splitting along each of the three attributes. \n",
    "\n",
    "The one with the highest information gain would be the one chosen for the first split. For a full decision tree, you would subsequently split each class along the attribute with the largest information gain recursively until no further splitting is possible (that is, you end up with pure classes with no mixing). This can be a bit of a challenge from the perspective of managing data structures, thus you'll just be working with a library for constructing full decision trees in this HW. This is just a taste of how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Dropbox/All_Work_Files/Teaching/2024/Q520/HW/Q520_Winter24_Env`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Dropbox/All_Work_Files/Teaching/2024/Q520/HW/Q520_Winter24_Env/Project.toml`\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[336ed68f] \u001b[39mCSV v0.10.11\n",
      "  \u001b[90m[a93c6f00] \u001b[39mDataFrames v1.6.1\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[31c24e10] \u001b[39mDistributions v0.25.104\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[033835bb] \u001b[39mJLD2 v0.4.38\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[91a5bcdd] \u001b[39mPlots v1.39.0\n",
      "  \u001b[90m[2913bbd2] \u001b[39mStatsBase v0.34.2\n",
      "  \u001b[90m[f3b207a7] \u001b[39mStatsPlots v0.15.6\n",
      "  \u001b[90m[37e2e46d] \u001b[39mLinearAlgebra\n",
      "  \u001b[90m[9a3f8284] \u001b[39mRandom\n",
      "\u001b[36m\u001b[1mInfo\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m and \u001b[33m⌅\u001b[39m have new versions available. Those with \u001b[32m⌃\u001b[39m may be upgradable, but those with \u001b[33m⌅\u001b[39m are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10×4 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m Eat    \u001b[0m\u001b[1m Taste  \u001b[0m\u001b[1m Temperature \u001b[0m\u001b[1m Texture \u001b[0m\n",
      "     │\u001b[90m String \u001b[0m\u001b[90m String \u001b[0m\u001b[90m String      \u001b[0m\u001b[90m String  \u001b[0m\n",
      "─────┼──────────────────────────────────────\n",
      "   1 │ No      Salty   Hot          Soft\n",
      "   2 │ No      Spicy   Hot          Soft\n",
      "   3 │ Yes     Spicy   Hot          Hard\n",
      "   4 │ No      Spicy   Cold         Hard\n",
      "   5 │ Yes     Spicy   Hot          Hard\n",
      "   6 │ Yes     Sweet   Cold         Soft\n",
      "   7 │ No      Salty   Cold         Soft\n",
      "   8 │ Yes     Sweet   Hot          Soft\n",
      "   9 │ Yes     Spicy   Cold         Soft\n",
      "  10 │ Yes     Salty   Hot          Hard\n"
     ]
    }
   ],
   "source": [
    "using DataFrames\n",
    "\n",
    "dataset = Dict(\n",
    "    \"Taste\" => [\"Salty\", \"Spicy\", \"Spicy\", \"Spicy\", \"Spicy\", \"Sweet\", \"Salty\", \"Sweet\", \"Spicy\", \"Salty\"],\n",
    "    \"Temperature\" => [\"Hot\", \"Hot\", \"Hot\", \"Cold\", \"Hot\", \"Cold\", \"Cold\", \"Hot\", \"Cold\", \"Hot\"],\n",
    "    \"Texture\" => [\"Soft\", \"Soft\", \"Hard\", \"Hard\", \"Hard\", \"Soft\", \"Soft\", \"Soft\", \"Soft\", \"Hard\"],\n",
    "    \"Eat\" => [\"No\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\"]\n",
    ")\n",
    "\n",
    "df = DataFrame(dataset)\n",
    "\n",
    "println(first(df, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entropy Log e = \n"
     ]
    }
   ],
   "source": [
    "\n",
    "println(\"Total Entropy Log e = \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `calculate_entropy` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `calculate_entropy` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Dropbox/All_Work_Files/Teaching/2024/Q520/HW/InformationTheory/Problem_Notebooks/Tree_IG.ipynb:6"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "attribute_list = [\"Taste\", \"Temperature\", \"Texture\"]\n",
    "\n",
    "for attribute in attribute_list\n",
    "    result = calculate_entropy(df, attribute)\n",
    "    println(\"$attribute Information Gain Log e = $(entropy_node - result)\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
