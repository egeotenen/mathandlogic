{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy and cross entropy of \"High Flight\"\n",
    "\n",
    "High Flight is a famous poem. Read in the contents of 'HighFlight.txt' as a list of characters. Calculate the following.\n",
    "\n",
    "1) What is the entropy of the characters in this poem (including the special characters for simplicity)? \n",
    "\n",
    "2) Suppose these characters appeared uniformly, you would expect the entropy to be higher. What would the entropy for the set of characters contained in this poem be if they were uniformly distributed.\n",
    "\n",
    "3) Let p be the frequency distribution of characters in the poem and q be the uniform frequency distribution of those characters. Calculate H(p,q) and H(q,p) (the respective cross entropies) along with KL(p||q) and KL(q||p) (the KL divergences). Verify that H(p,q) = H(p) + KL(p||q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using Pkg\n",
    "using StatsBase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet of symbols in the string:\n",
      "Set(['E', 'i', 's', ',', 'O', '\\'', 'W', 'T', 'y', 'k', 'S', 'w', 'r', ';', 'c', 'U', 'e', 'j', 'n', 'f', 'M', '-', 'b', '!', 'A', ' ', 'g', 'h', 'P', 'I', 'H', 'a', 'p', 'd', 'G', 't', '.', 'v', 'm', 'o', '\\r', 'u', 'Y', 'l'])\n",
      "44"
     ]
    }
   ],
   "source": [
    "# Here is some seed code to open the file, get the text, and collect the set of unique symbols\n",
    "\n",
    "f = open(\"HighFlight.txt\", \"r\")\n",
    "contents = read(f, String)\n",
    "close(f)\n",
    "\n",
    "stList = collect(contents)\n",
    "alphabet = Set(stList)  # set of symbols in the string\n",
    "println(\"Alphabet of symbols in the string:\")\n",
    "println(alphabet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poem_length = length(contents)\n",
    "num_chars = length(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Entropy for characters in poem:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1374749890781697\n"
     ]
    }
   ],
   "source": [
    "println(\"1. Entropy for characters in poem:\")\n",
    "p = countmap(stList)\n",
    "p = collect(values(p))\n",
    "p = p ./ poem_length\n",
    "entropy = - sum(p .* log.(p))\n",
    "println(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Entropy if each character was equally likely:\n",
      "3.784189633918261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "println(\"2. Entropy if each character was equally likely:\")\n",
    "entropy_uni = - log(1/num_chars)\n",
    "println(entropy_uni)\n",
    "println()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropies:\n",
      "H(p, q): 3.784189633918261\n",
      "H(q, p): 4.662679575931986\n",
      "\n",
      "KL divergences:\n",
      "KL(p || q): 0.6467146448400913\n",
      "KL(q || p): 1.5252045868538167\n",
      "\n",
      "From direct calculation we find:\n",
      "H(p, q) = 3.784189633918261\n",
      "Composing entropy and KL yields:\n",
      "H(p) + KL(p||q) = 3.784189633918261\n"
     ]
    }
   ],
   "source": [
    "# Cross entropies:\n",
    "println(\"Cross entropies:\")\n",
    "q = ones(num_chars) ./ num_chars\n",
    "H_pq = - sum(p .* log.(q))\n",
    "H_qp = - sum(q .* log.(p))\n",
    "\n",
    "println(\"H(p, q): \", H_pq)\n",
    "println(\"H(q, p): \", H_qp)\n",
    "println()\n",
    "\n",
    "# KLs:\n",
    "println(\"KL divergences:\")\n",
    "KL_pq = H_pq - entropy\n",
    "KL_qp = H_qp - entropy\n",
    "\n",
    "println(\"KL(p || q): \", KL_pq)\n",
    "println(\"KL(q || p): \", KL_qp)\n",
    "println()\n",
    "\n",
    "# The rest\n",
    "println(\"From direct calculation we find:\")\n",
    "println(\"H(p, q) = \", H_pq)\n",
    "println(\"Composing entropy and KL yields:\")\n",
    "#println(\"H(p) + KL(p||q) = \", ...)\n",
    "#println(\"H(p, q) = \", H_pq)\n",
    "#println(\"Very small difference: \", ...)\n",
    "#println(\"H(p, q) = \", H_pq)\n",
    "\n",
    "# Verify that H(p,q) = H(p) + KL(p||q)\n",
    "println(\"H(p) + KL(p||q) = \", entropy + KL_pq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
