{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum entropy demonstration\n",
    "\n",
    "In class we discussed the maximum entropy principle. It says that given a set of assumptions, there is a distribution associated with those assumptions that has maximal entropy. In this assignment, you are going to demonstrate that the maximum entropy distribution for a variable with N outcomes is the multinomial distribution with equal weights on the outcmes.\n",
    "\n",
    "Assume there is a random variable with 6 possible outcomes. You know nothing about these outcomes or their frequencies. Do the following.\n",
    "\n",
    "1) Create a multinomial distribution assuming the outcomes are equally likely. Then compute its entropy. This is a concrete number that will be used for comparison.\n",
    "\n",
    "2) Iterate the following process for 100_000 replications. \n",
    "\n",
    "    Choose a collection of 6 random probabilities representing the 6 outcomes (note these 6 probabilities must add to 1; they are probabilities after all). For this random (but non uniform) distribution, compute the entropy.\n",
    "\n",
    "    You will do this 100_000 times with different random probability sets and thus end up with 100_000 entropies.\n",
    "\n",
    "3) Plot a histogram of all the entropies and overlay a plot of the value of the entropy for the uniform probability case. You should see something interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "PATH = \"../../Q520_Winter24_Env/\"\n",
    "Pkg.activate(PATH)\n",
    "Pkg.status()\n",
    "\n",
    "using Distributions\n",
    "using StatsPlots\n",
    "using StatsBase\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function multinomial_entropy(n,p)\n",
    "\n",
    "    return ent\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper plotting\n",
    "histogram(entropy_all,label=\"Random ps\") # Plots histogram\n",
    "\n",
    "# Plots entropy of uniform. Note the ylim=5000 may need to be changed by you\n",
    "# as it depends on the histogram height.\n",
    "plot!([entropy_uniform , entropy_uniform] , [0,5000],label = \"Uniform ps\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
